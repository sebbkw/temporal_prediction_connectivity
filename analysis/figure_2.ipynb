{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, sys\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# Import custom modules\n",
    "sys.path.append(\"../models\")\n",
    "from models.network_hierarchical_recurrent_temporal_prediction import NetworkHierarchicalRecurrentTemporalPrediction as Network\n",
    "\n",
    "from virtual_physiology.VirtualNetworkPhysiology import VirtualPhysiology\n",
    "from plotting_functions import *\n",
    "from connectivity_functions import *\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Add model and vphys paths here\n",
    "MODEL_PATH = ''\n",
    "VPHYS_PATH = ''\n",
    "MODEL_NAME = ''\n",
    "\n",
    "TOTAL_UNITS      = 2*36*36\n",
    "EXCITATORY_UNITS = int(TOTAL_UNITS*0.9)\n",
    "INHIBITORY_UNITS = TOTAL_UNITS-EXCITATORY_UNITS\n",
    "\n",
    "# Load network checkpoint\n",
    "model, hyperparameters, _ = Network.load(\n",
    "    model_path=MODEL_PATH, device='cpu', plot_loss_history=True\n",
    ")\n",
    "\n",
    "# Instantiate new VirtualPhysiology object\n",
    "vphys = VirtualPhysiology.load(\n",
    "    data_path=VPHYS_PATH,\n",
    "    model=model,\n",
    "    hyperparameters=hyperparameters,\n",
    "    frame_shape=(36,36),\n",
    "    hidden_units=[2592],\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "excitatory_units = [u for u in vphys.data[0] if u['hidden_unit_index'] <  EXCITATORY_UNITS]\n",
    "inhibitory_units = [u for u in vphys.data[0] if u['hidden_unit_index'] >= EXCITATORY_UNITS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cochrane_armitage (data_a, data_b):\n",
    "    contingency_table = {idx: [a, b] for idx, (a, b) in enumerate(zip(data_a, data_b)) }\n",
    "    contingency_table_pd = pd.DataFrame(contingency_table, index=[0, 1])\n",
    "    contingency_table_sm = sm.stats.Table(contingency_table_pd)\n",
    "\n",
    "    return contingency_table_sm.test_ordinal_association(\n",
    "        row_scores=np.array([0,1]),\n",
    "        col_scores=np.arange(len(data_a)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_units   = 36*36*2\n",
    "excit_units_n = int(total_units*0.9)\n",
    "weight_matrix = model.rnn.weight_hh_l0.detach().numpy()\n",
    "weight_matrix = weight_matrix[:excit_units_n, :excit_units_n]\n",
    "\n",
    "threshold = np.percentile(np.abs(weight_matrix.reshape(-1)), 95)\n",
    "\n",
    "all_units     = []\n",
    "for unit in vphys.data[0]:\n",
    "    if unit['hidden_unit_index'] < excit_units_n:\n",
    "        r = unit['gabor_r']\n",
    "        sx, sy = unit['gabor_params'][4:6]\n",
    "\n",
    "        if unit['gabor_r'] > 0.7 and sx>0.5 and sy>0.5:\n",
    "            all_units.append(unit)        \n",
    "        \n",
    "ALL_MODES = [\n",
    "    ['short_range', 'all', 'orientation', [10, 11, 4], [26, 44, 24]],\n",
    "    ['short_range', 'all', 'direction',   [6, 3, 4, 4, 2], [13, 16, 22, 16, 5]],\n",
    "]\n",
    "\n",
    "for CONNECTION_DISTANCE_MODE, CONNECTION_AXIS_MODE, ORIENTATION_MODE, NEURAL_DATA_A, NEURAL_DATA_B in ALL_MODES:\n",
    "    NEURAL_DATA = np.array(NEURAL_DATA_A)/np.array(NEURAL_DATA_B)\n",
    "    \n",
    "    all_orientation_differences = []\n",
    "    all_post_unit_orientations  = []\n",
    "    all_pre_unit_orientations   = []\n",
    "    all_weights = []\n",
    "\n",
    "    for post_unit_idx, post_unit in enumerate(all_units):    \n",
    "        if (post_unit_idx % 200) == 0:\n",
    "            print('Starting unit', post_unit_idx, '/',  len(all_units))\n",
    "        \n",
    "        all_pre_units     = []\n",
    "        \n",
    "        for pre_unit_idx, pre_unit in enumerate(all_units):\n",
    "            is_in_range       = get_is_in_range(pre_unit, post_unit, CONNECTION_DISTANCE_MODE)\n",
    "            is_connected, w   = get_is_connected(pre_unit, post_unit, weight_matrix, threshold)\n",
    "            is_different_unit = pre_unit_idx != post_unit_idx\n",
    "            is_selective      = is_orientation_or_direction_selective(pre_unit, post_unit, ORIENTATION_MODE)\n",
    "\n",
    "            if is_in_range and is_different_unit and is_selective:\n",
    "                all_pre_units.append(pre_unit)\n",
    "                       \n",
    "        translation_matrix           = get_translation_matrix(post_unit)\n",
    "        rotation_matrix              = get_rotation_matrix(post_unit)\n",
    "        transformation               = rotation_matrix@translation_matrix\n",
    "        all_pre_units_transformed    = apply_matrix_transformation(all_pre_units, transformation)\n",
    "        all_pre_units_filtered       = apply_axis_filter(all_pre_units_transformed, CONNECTION_AXIS_MODE)\n",
    "        orientation_differences      = get_orientation_differences(post_unit, all_pre_units_filtered, ORIENTATION_MODE)        \n",
    "        \n",
    "        all_orientation_differences += orientation_differences\n",
    "        all_weights                 += [abs(get_is_connected(u, post_unit, weight_matrix, threshold)[1]) for u in all_pre_units_filtered]\n",
    "    \n",
    "        for u in all_pre_units_filtered:\n",
    "            all_post_unit_orientations.append(post_unit['preferred_orientation'])\n",
    "            all_pre_unit_orientations.append(u['preferred_orientation'])\n",
    "\n",
    "    \n",
    "    all_orientation_differences      = np.array(all_orientation_differences)\n",
    "    all_weights                      = np.array(all_weights)\n",
    "    all_post_unit_orientations       = np.array(all_post_unit_orientations)\n",
    "    all_pre_unit_orientations        = np.array(all_pre_unit_orientations)\n",
    "    \n",
    "    bins        = [0, 22.5, 67.5, 112.5, 157.5, 180] if ORIENTATION_MODE == 'direction' else [0, 22.5, 67.5, 90] # [0, 30, 90]\n",
    "    bin_centres = [0, 45, 90, 135, 180] if ORIENTATION_MODE == 'direction' else [0, 45, 90]\n",
    "    x_ticks     = np.arange(len(bin_centres))\n",
    "\n",
    "    connected_binned_data, _  = np.histogram(all_orientation_differences[all_weights>threshold], bins=bins)\n",
    "    all_binned_data, _        = np.histogram(all_orientation_differences, bins=bins)\n",
    "    true_dist                 = connected_binned_data/all_binned_data\n",
    "        \n",
    "    if ORIENTATION_MODE == 'orientation':        \n",
    "        print(get_cochrane_armitage(connected_binned_data, all_binned_data))\n",
    "    else:\n",
    "        print(get_cochrane_armitage(connected_binned_data[:3], all_binned_data[:3]))\n",
    "        print(get_cochrane_armitage(connected_binned_data[2:], all_binned_data[2:]))\n",
    "        \n",
    "    save_connectivity_data(\n",
    "        model_name   = MODEL_NAME,\n",
    "        measure_name = f'{CONNECTION_DISTANCE_MODE}_{CONNECTION_AXIS_MODE}_{ORIENTATION_MODE}',\n",
    "        model        = true_dist,\n",
    "        target       = NEURAL_DATA\n",
    "    )\n",
    "        \n",
    "    fig = plt.figure()    \n",
    "    plt.bar(x_ticks-1/3, true_dist, facecolor='black', width=1/3)        \n",
    "    plt.bar(x_ticks, NEURAL_DATA, facecolor='gray', width=1/3)\n",
    "    plt.xticks(x_ticks-1/6, bin_centres)\n",
    "    plt.xlabel(f\"{'Orientation' if ORIENTATION_MODE == 'orientation' else 'Direction'} difference (°)\")\n",
    "    plt.ylabel('Connection probability')    \n",
    "    plt.ylim(0, 0.5)\n",
    "    format_plot(fontsize=20)\n",
    "    fig.set_size_inches(4,4)\n",
    "    save_plot(2, f'{CONNECTION_DISTANCE_MODE}_{CONNECTION_AXIS_MODE}_{ORIENTATION_MODE}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhibitory units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_units   = 36*36*2\n",
    "excit_units_n = int(total_units*0.9)\n",
    "weight_matrix = model.rnn.weight_hh_l0.detach().numpy()\n",
    "\n",
    "weight_matrix_exc_exc_subset = weight_matrix[:excit_units_n, :excit_units_n]\n",
    "threshold_exc_exc = np.percentile(np.abs(weight_matrix_exc_exc_subset.reshape(-1)), 95)\n",
    "\n",
    "weight_matrix_exc_inh_subset = weight_matrix[excit_units_n:total_units, :excit_units_n]\n",
    "threshold_exc_inh = np.percentile(np.abs(weight_matrix_exc_exc_subset.reshape(-1)), 95)\n",
    "\n",
    "weight_matrix_inh_exc_subset = weight_matrix[:excit_units_n, excit_units_n:total_units]\n",
    "threshold_inh_exc = np.percentile(np.abs(weight_matrix_exc_inh_subset.reshape(-1)), 95)\n",
    "\n",
    "weight_matrix_inh_inh_subset = weight_matrix[excit_units_n:total_units, excit_units_n:total_units]\n",
    "threshold_inh_inh = np.percentile(np.abs(weight_matrix_inh_inh_subset.reshape(-1)), 95)\n",
    "\n",
    "exc_units     = []\n",
    "inh_units     = []\n",
    "for unit in vphys.data[0]:\n",
    "    r = unit['gabor_r']\n",
    "    sx, sy = unit['gabor_params'][4:6]\n",
    "\n",
    "    if unit['gabor_r'] > 0.7 and sx>0.5 and sy>0.5:\n",
    "        if unit['hidden_unit_index'] < excit_units_n:\n",
    "            exc_units.append(unit)\n",
    "        else:\n",
    "            inh_units.append(unit)\n",
    "\n",
    "\n",
    "TRUE_DIST_ARR = []\n",
    "            \n",
    "        \n",
    "ALL_MODES = [\n",
    "    ['short_range', 'all', 'orientation', exc_units, exc_units, threshold_exc_exc],\n",
    "    ['short_range', 'all', 'orientation', exc_units, inh_units, threshold_exc_inh],\n",
    "    #['short_range', 'all', 'direction', inh_units, exc_units, threshold_inh_exc],\n",
    "    #['short_range', 'all', 'direction', inh_units, inh_units, threshold_inh_inh],\n",
    "]\n",
    "\n",
    "for CONNECTION_DISTANCE_MODE, CONNECTION_AXIS_MODE, ORIENTATION_MODE, PRE_UNITS, POST_UNITS, THRESHOLD in ALL_MODES:\n",
    "    all_orientation_differences = []\n",
    "    all_post_unit_orientations  = []\n",
    "    all_pre_unit_orientations   = []\n",
    "    all_weights = []\n",
    "\n",
    "    for post_unit_idx, post_unit in enumerate(POST_UNITS):    \n",
    "        if (post_unit_idx % 200) == 0:\n",
    "            print('Starting unit', post_unit_idx, '/',  len(POST_UNITS))\n",
    "        \n",
    "        all_pre_units     = []\n",
    "        \n",
    "        for pre_unit_idx, pre_unit in enumerate(PRE_UNITS):\n",
    "            is_in_range       = get_is_in_range(pre_unit, post_unit, CONNECTION_DISTANCE_MODE)\n",
    "            is_connected, w   = get_is_connected(pre_unit, post_unit, weight_matrix, THRESHOLD)\n",
    "            is_different_unit = pre_unit_idx != post_unit_idx\n",
    "            is_selective      = is_orientation_or_direction_selective(pre_unit, post_unit, ORIENTATION_MODE)\n",
    "\n",
    "            if is_in_range and is_different_unit and is_selective:\n",
    "                all_pre_units.append(pre_unit)\n",
    "                                              \n",
    "        if not len(all_pre_units):\n",
    "            continue\n",
    "                       \n",
    "        translation_matrix           = get_translation_matrix(post_unit)\n",
    "        rotation_matrix              = get_rotation_matrix(post_unit)\n",
    "        transformation               = rotation_matrix@translation_matrix\n",
    "        all_pre_units_transformed    = apply_matrix_transformation(all_pre_units, transformation)\n",
    "        all_pre_units_filtered       = apply_axis_filter(all_pre_units_transformed, CONNECTION_AXIS_MODE)\n",
    "        orientation_differences      = get_orientation_differences(post_unit, all_pre_units_filtered, ORIENTATION_MODE)        \n",
    "        \n",
    "        all_orientation_differences += orientation_differences\n",
    "        all_weights                 += [abs(get_is_connected(u, post_unit, weight_matrix, THRESHOLD)[1]) for u in all_pre_units_filtered]\n",
    "    \n",
    "        for u in all_pre_units_filtered:\n",
    "            all_post_unit_orientations.append(post_unit['preferred_orientation'])\n",
    "            all_pre_unit_orientations.append(u['preferred_orientation'])\n",
    "    \n",
    "    all_orientation_differences      = np.array(all_orientation_differences)\n",
    "    all_weights                      = np.array(all_weights)\n",
    "    all_post_unit_orientations       = np.array(all_post_unit_orientations)\n",
    "    all_pre_unit_orientations        = np.array(all_pre_unit_orientations)\n",
    "    \n",
    "    bins        = [0, 22.5, 67.5, 90] \n",
    "    bin_centres =  [0, 45, 90]\n",
    "    #bins        = [0, 22.5, 67.5, 112.5, 157.5, 180]\n",
    "    #bin_centres = [0, 45, 90, 135, 180]\n",
    "    x_ticks     = np.arange(len(bin_centres))\n",
    "\n",
    "    connected_binned_data, _  = np.histogram(all_orientation_differences[all_weights>THRESHOLD], bins=bins)\n",
    "    all_binned_data, _        = np.histogram(all_orientation_differences, bins=bins)\n",
    "    true_dist                 = connected_binned_data/all_binned_data\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    print(get_cochrane_armitage(connected_binned_data, all_binned_data))\n",
    "    print('\\n\\n')\n",
    "        \n",
    "    TRUE_DIST_ARR.append(true_dist)\n",
    "\n",
    "fig = plt.figure() \n",
    "\n",
    "for offset, true_dist, color, label, hatch, alpha in zip(\n",
    "    [-1/3, 0],\n",
    "    TRUE_DIST_ARR,\n",
    "    ['tab:red', 'tab:red'],\n",
    "    #['tab:blue', 'tab:blue'],\n",
    "    ['Exc→exc', 'Exc→inh'],\n",
    "    #['Inh→exc', 'Inh→inh'],\n",
    "    ['', '/'],\n",
    "    [1, 0.75]\n",
    "):\n",
    "        plt.bar(x_ticks+offset, true_dist, facecolor=color, width=1/3, edgecolor='black', hatch=hatch, alpha=alpha) #, label=label)    \n",
    "\n",
    "plt.xticks(x_ticks, bin_centres)\n",
    "plt.xlabel(\"Direction difference (°)\")\n",
    "plt.ylabel('Connection probability')\n",
    "plt.ylim(0, 0.6)\n",
    "\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(4,4)\n",
    "plt.gca().get_legend().set_bbox_to_anchor((1, 1))\n",
    "#save_plot(2, f'excitatory_excitatory_{CONNECTION_DISTANCE_MODE}_{CONNECTION_AXIS_MODE}_{ORIENTATION_MODE}')\n",
    "save_plot(2, f'inhibitory_inhibitory_{CONNECTION_DISTANCE_MODE}_{CONNECTION_AXIS_MODE}_{ORIENTATION_MODE}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iacoruso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffled_binned_data_iacoruso (post_unit_orientations, pre_unit_orientations, bins, total_units):\n",
    "    iters = 10000\n",
    "    shuffled_results = np.zeros((len(bins)-1, iters))\n",
    "    \n",
    "    pre_unit_orientations_copy = pre_unit_orientations.copy()\n",
    "    \n",
    "    for i in range(iters):\n",
    "        if i % 1000 == 0:\n",
    "            print('Iteration', i)\n",
    "            \n",
    "        np.random.shuffle(pre_unit_orientations_copy)\n",
    "                \n",
    "        orientation_differences = []\n",
    "        for a1, a2 in zip(post_unit_orientations, pre_unit_orientations_copy):\n",
    "            freq_diff = abs((a1%180)-(a2%180))\n",
    "            freq_diff = min(freq_diff, 180-freq_diff)\n",
    "            orientation_differences.append(freq_diff)\n",
    "\n",
    "        binned_data, _ = np.histogram(orientation_differences, bins=bins)\n",
    "\n",
    "        shuffled_results[:, i] = binned_data/total_units\n",
    "        \n",
    "    return shuffled_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_units   = 36*36*2\n",
    "excit_units_n = int(total_units*0.9)\n",
    "weight_matrix = model.rnn.weight_hh_l0[:excit_units_n, :excit_units_n].detach().numpy()\n",
    "\n",
    "threshold = np.percentile(weight_matrix.reshape(-1), 95)\n",
    "\n",
    "all_units     = []\n",
    "for unit in vphys.data[0]:\n",
    "    if unit['hidden_unit_index'] < excit_units_n:\n",
    "        r = unit['gabor_r']\n",
    "        sx, sy = unit['gabor_params'][4:6]\n",
    "\n",
    "        if unit['gabor_r'] > 0.7 and sx>0.5 and sy>0.5:\n",
    "            all_units.append(unit)\n",
    "        \n",
    "        \n",
    "ALL_MODES = [\n",
    "    ['long_range', 'coaxial', 'orientation'],\n",
    "    ['long_range', 'orthogonal', 'orientation']\n",
    "]\n",
    "\n",
    "axial_results = {\n",
    "    'orientation_differences': [],\n",
    "    'post_unit_orientations' : [],\n",
    "    'pre_unit_orientations'  : [],        \n",
    "    'neural_data_a'          : [[48, 33, 16], [20, 19, 23]],\n",
    "    'neural_data_b'          : [[159, 159, 159], [159, 159, 159]],\n",
    "    'save_string'            : ['long_range_coaxial_orientation', 'long_range_orthogonal_orientation']\n",
    "}\n",
    "\n",
    "for CONNECTION_DISTANCE_MODE, CONNECTION_AXIS_MODE, ORIENTATION_MODE in ALL_MODES:\n",
    "    all_orientation_differences = []\n",
    "    all_post_unit_orientations  = []\n",
    "    all_pre_unit_orientations   = []\n",
    "\n",
    "    for post_unit_idx, post_unit in enumerate(all_units):\n",
    "        if post_unit['gabor_x'] > 26 or post_unit['gabor_x'] < 10:\n",
    "            continue\n",
    "        if post_unit['gabor_y'] > 26 or post_unit['gabor_y'] < 10:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        if (post_unit_idx % 200) == 0:\n",
    "            print('Starting unit', post_unit_idx, '/',  len(all_units))\n",
    "        \n",
    "        all_pre_units     = []\n",
    "        \n",
    "        for pre_unit_idx, pre_unit in enumerate(all_units):\n",
    "            is_in_range       = get_is_in_range(pre_unit, post_unit, CONNECTION_DISTANCE_MODE)\n",
    "            is_connected, w   = get_is_connected(pre_unit, post_unit, weight_matrix, threshold)\n",
    "            is_different_unit = pre_unit_idx != post_unit_idx\n",
    "            is_selective      = is_orientation_or_direction_selective(pre_unit, post_unit, ORIENTATION_MODE)\n",
    "\n",
    "            if is_in_range and is_different_unit and is_selective and is_connected:\n",
    "                all_pre_units.append(pre_unit)\n",
    "                                              \n",
    "        if not len(all_pre_units):\n",
    "            continue\n",
    "                       \n",
    "        translation_matrix           = get_translation_matrix(post_unit)\n",
    "        rotation_matrix              = get_rotation_matrix(post_unit)\n",
    "        transformation               = rotation_matrix@translation_matrix\n",
    "        all_pre_units_transformed    = apply_matrix_transformation(all_pre_units, transformation)\n",
    "        all_pre_units_filtered       = apply_axis_filter(all_pre_units_transformed, CONNECTION_AXIS_MODE)\n",
    "        orientation_differences      = get_orientation_differences(post_unit, all_pre_units_filtered, ORIENTATION_MODE)        \n",
    "        \n",
    "        all_orientation_differences += orientation_differences\n",
    "    \n",
    "        for u in all_pre_units_filtered:\n",
    "            all_post_unit_orientations.append(post_unit['preferred_orientation'])\n",
    "            all_pre_unit_orientations.append(u['preferred_orientation'])\n",
    "    \n",
    "    all_orientation_differences      = np.array(all_orientation_differences)\n",
    "    all_post_unit_orientations       = np.array(all_post_unit_orientations)\n",
    "    all_pre_unit_orientations        = np.array(all_pre_unit_orientations)\n",
    "    \n",
    "    axial_results['orientation_differences'].append(all_orientation_differences)\n",
    "    axial_results['post_unit_orientations'].append(all_post_unit_orientations)\n",
    "    axial_results['pre_unit_orientations'].append(all_pre_unit_orientations)\n",
    "\n",
    "total_units = np.concatenate(axial_results['orientation_differences']).shape[0]\n",
    "\n",
    "for orientation_differences, post_unit_orientations, pre_unit_orientations, neural_data_a, neural_data_b, save_string in zip(*axial_results.values()):    \n",
    "    neural_data = np.array(neural_data_a)/np.array(neural_data_b)\n",
    "    \n",
    "    bins        = [0, 22.5, 67.5, 90]\n",
    "    bin_centres = [0, 45, 90]\n",
    "    x_ticks     = np.arange(len(bin_centres))\n",
    "    \n",
    "    connected_binned_data, _  = np.histogram(orientation_differences, bins=bins)    \n",
    "    true_fraction             = connected_binned_data/total_units\n",
    "    null_dist                 = get_shuffled_binned_data_iacoruso(\n",
    "        post_unit_orientations, pre_unit_orientations, bins, total_units\n",
    "    )\n",
    "        \n",
    "    save_connectivity_data(\n",
    "        model_name   = MODEL_NAME,\n",
    "        measure_name = save_string,\n",
    "        model        = true_fraction,\n",
    "        target       = neural_data\n",
    "    )\n",
    "\n",
    "    print(true_fraction)\n",
    "    print(np.percentile(null_dist, 2.5, axis=1))\n",
    "    print(np.percentile(null_dist, 97.5, axis=1))\n",
    "    p_vals = [get_p_val(true_fraction[i], null_dist[i]) for i in range(len(connected_binned_data))]\n",
    "    print(p_vals)\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    plt.bar(x_ticks-1/3, true_fraction, facecolor='black', width=1/3) \n",
    "    plt.bar(x_ticks, neural_data, facecolor='gray', width=1/3)\n",
    "    \n",
    "    plt.xticks(x_ticks-1/6, bin_centres)\n",
    "    plt.xlabel(f\"{'Orientation' if ORIENTATION_MODE == 'orientation' else 'Direction'} difference (°)\")\n",
    "    plt.ylabel('Presynaptic fraction')\n",
    "    plt.ylim(0, 0.3)\n",
    "    format_plot(fontsize=20)\n",
    "    fig.set_size_inches(4,4)\n",
    "    save_plot(2, f'{save_string}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ori_diffs (a, b, bins):\n",
    "    orientation_differences = []\n",
    "    for a1, a2 in zip(a, b):\n",
    "        freq_diff = abs((a1%180)-(a2%180))\n",
    "        freq_diff = min(freq_diff, 180-freq_diff)\n",
    "        orientation_differences.append(freq_diff)\n",
    "    binned_data, _ = np.histogram(orientation_differences, bins=bins)\n",
    "        \n",
    "    return binned_data\n",
    "\n",
    "\n",
    "def get_shuffled_binned_data_iacoruso_2g (\n",
    "    post_unit_orientations_axial,\n",
    "    pre_unit_orientations_axial,\n",
    "    post_unit_orientations_ortho,\n",
    "    pre_unit_orientations_ortho,\n",
    "    bins\n",
    "):\n",
    "    iters = 10000\n",
    "    shuffled_results = np.zeros((len(bins)-1, iters))\n",
    "    \n",
    "    all_post = np.concatenate([post_unit_orientations_axial, post_unit_orientations_ortho], axis=0)\n",
    "    all_pre  = np.concatenate([pre_unit_orientations_axial, pre_unit_orientations_ortho], axis=0)\n",
    "    \n",
    "    axial_binned = get_ori_diffs(post_unit_orientations_axial, pre_unit_orientations_axial, bins)\n",
    "    ortho_binned = get_ori_diffs(post_unit_orientations_ortho, pre_unit_orientations_ortho, bins)\n",
    "    test_stat    = axial_binned-ortho_binned\n",
    "        \n",
    "    for i in range(iters):\n",
    "        if i % 1000 == 0:\n",
    "            print('Iteration', i)\n",
    "            \n",
    "        np.random.shuffle(all_post)\n",
    "        np.random.shuffle(all_pre)\n",
    "            \n",
    "        post_axial_sample = []\n",
    "        post_ortho_sample = []\n",
    "        \n",
    "        pre_axial_sample = []\n",
    "        pre_ortho_sample = []\n",
    "            \n",
    "        axial_binned = get_ori_diffs(all_post[:len(post_unit_orientations_axial)], all_pre[:len(post_unit_orientations_axial)], bins)\n",
    "        ortho_binned = get_ori_diffs(all_post[len(post_unit_orientations_axial):], all_pre[len(post_unit_orientations_axial):], bins)\n",
    "        rand_stat    = axial_binned-ortho_binned\n",
    "\n",
    "        shuffled_results[:, i] = rand_stat\n",
    "        \n",
    "    return test_stat, shuffled_results\n",
    "\n",
    "test_stat, null_dist = get_shuffled_binned_data_iacoruso_2g (\n",
    "    axial_results['post_unit_orientations'][0],\n",
    "    axial_results['pre_unit_orientations'][0],\n",
    "    axial_results['post_unit_orientations'][1],\n",
    "    axial_results['pre_unit_orientations'][1],\n",
    "    bins\n",
    ")\n",
    "\n",
    "print(test_stat)\n",
    "print(np.percentile(null_dist, 2.5, axis=1))\n",
    "print(np.percentile(null_dist, 97.5, axis=1))\n",
    "p_vals = [get_p_val(test_stat[i], null_dist[i]) for i in range(3)]\n",
    "print(p_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmaps (m, nan_mask, cmap_str):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(bins)-1, dpi=100, figsize=[6, 4])\n",
    "    \n",
    "    final_ims = []\n",
    "    for h_idx, h in enumerate(m):\n",
    "        filt = ndimage.gaussian_filter(np.nan_to_num(h.copy(), 0), 2).reshape(-1)\n",
    "        filt[nan_mask] = np.nan\n",
    "        filt = filt.reshape(h.shape)\n",
    "        final_ims.append(filt)\n",
    "        \n",
    "    vmax = np.nanmax([np.nanmax(h) for h in final_ims])\n",
    "    vmin = np.nanmin([np.nanmin(h) for h in final_ims])\n",
    "        \n",
    "    for h_idx, (h, ax) in enumerate(zip(final_ims, axs)):\n",
    "        cmap = ax.imshow(h, origin='lower', cmap=cmap_str, vmax=vmax, vmin=vmin, interpolation=None)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.spines['top'].set_visible(True)\n",
    "        if h_idx == len(bins)-2:\n",
    "            ticks = [round(vmin, 2), round((vmin+vmax)/2, 2), round(vmax-0.01, 2)]\n",
    "            cbar = plt.colorbar(cmap, cax=fig.add_axes([1, 0.275, 0.03, 0.45]), ticks=ticks)\n",
    "            cbar.ax.tick_params(labelsize=20)    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_units   = 36*36*2\n",
    "excit_units_n = int(total_units*0.9)\n",
    "weight_matrix = model.rnn.weight_hh_l0[:excit_units_n, :excit_units_n].detach().numpy()\n",
    "\n",
    "threshold = np.percentile(weight_matrix.reshape(-1), 95)\n",
    "\n",
    "all_units     = []\n",
    "for unit in vphys.data[0]:\n",
    "    if unit['hidden_unit_index'] < excit_units_n:\n",
    "        r = unit['gabor_r']\n",
    "        sx, sy = unit['gabor_params'][4:6]\n",
    "\n",
    "        if unit['gabor_r'] > 0.7 and sx>0.5 and sy>0.5:\n",
    "            all_units.append(unit)\n",
    "        \n",
    "\n",
    "ALL_MODES = [\n",
    "    ['long_range', 'all', 'orientation'],\n",
    "]\n",
    "\n",
    "for CONNECTION_DISTANCE_MODE, CONNECTION_AXIS_MODE, ORIENTATION_MODE in ALL_MODES:\n",
    "    all_orientation_differences = []\n",
    "    all_weights = []\n",
    "    all_coords = []\n",
    "  \n",
    "    for post_unit_idx, post_unit in enumerate(all_units):\n",
    "        if post_unit['gabor_x'] > 26 or post_unit['gabor_x'] < 10:\n",
    "            continue\n",
    "        if post_unit['gabor_y'] > 26 or post_unit['gabor_y'] < 10:\n",
    "            continue    \n",
    "            \n",
    "        \n",
    "        if (post_unit_idx % 200) == 0:\n",
    "            print('Starting unit', post_unit_idx, '/',  len(all_units))\n",
    "        \n",
    "        all_pre_units     = []\n",
    "        \n",
    "        for pre_unit_idx, pre_unit in enumerate(all_units):            \n",
    "            is_in_range       = get_is_in_range(pre_unit, post_unit, CONNECTION_DISTANCE_MODE)\n",
    "            is_connected, w   = get_is_connected(pre_unit, post_unit, weight_matrix, threshold)\n",
    "            is_different_unit = pre_unit_idx != post_unit_idx\n",
    "            is_selective      = is_orientation_or_direction_selective(pre_unit, post_unit, ORIENTATION_MODE)\n",
    "\n",
    "            if is_in_range and is_different_unit and is_selective:\n",
    "                all_pre_units.append(pre_unit)\n",
    "                              \n",
    "        if not len(all_pre_units):\n",
    "            continue\n",
    "            \n",
    "        translation_matrix           = get_translation_matrix(post_unit)\n",
    "        rotation_matrix              = get_rotation_matrix(post_unit)\n",
    "        transformation               = rotation_matrix@translation_matrix\n",
    "        all_pre_units_transformed    = apply_matrix_transformation(all_pre_units, transformation)\n",
    "        all_pre_units_filtered       = apply_axis_filter(all_pre_units_transformed, CONNECTION_AXIS_MODE)\n",
    "        orientation_differences      = get_orientation_differences(post_unit, all_pre_units_filtered, ORIENTATION_MODE)\n",
    "\n",
    "        all_orientation_differences += orientation_differences\n",
    "        all_weights                 += [get_is_connected(u, post_unit, weight_matrix, threshold)[1] for u in all_pre_units_filtered]\n",
    "        all_coords                  += [{'x': u['gabor_x'], 'y': u['gabor_y']} for u in all_pre_units_filtered]    \n",
    "    \n",
    "    all_orientation_differences      = np.array(all_orientation_differences)\n",
    "    all_weights                      = np.array(all_weights)\n",
    "    all_coords                       = np.array(all_coords)\n",
    "\n",
    "    bins               = [0, 22.5, 67.5, 90]\n",
    "    true_heat_maps     = get_heat_maps(all_orientation_differences, all_coords, all_weights, bins, threshold)\n",
    "    all_heat_maps      = get_heat_maps(all_orientation_differences, all_coords, all_weights, bins, 0)\n",
    "\n",
    "    normalized_heat_maps = true_heat_maps/all_heat_maps\n",
    "    heat_maps_to_use = normalized_heat_maps\n",
    "    \n",
    "    nan_mask = np.argwhere(np.isnan(normalized_heat_maps[0].reshape(-1)))[:, 0]\n",
    "    \n",
    "    plot_heatmaps(normalized_heat_maps, nan_mask, cmap_str='viridis')\n",
    "    save_plot(2, 'heatmap')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural movies response correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffled_binned_data_cossel_conprob (res_corr, is_connected_arr, bins):\n",
    "    n_connected = np.sum(is_connected_arr==1)\n",
    "    \n",
    "    iters = 1000\n",
    "    shuffled_results = np.zeros((len(bins)-1, iters))\n",
    "    \n",
    "    for i in range(iters):\n",
    "        if i % 10 == 0:\n",
    "            print('Iteration', i)\n",
    "        \n",
    "        temp_binned_data, _ = np.histogram(np.random.choice(res_corr, size=n_connected, replace=False), bins=bins)\n",
    "        shuffled_results[:, i] = temp_binned_data\n",
    "        \n",
    "    return shuffled_results\n",
    "\n",
    "def get_shuffled_binned_data_cossel_constr (res_corr, conn_str, bins):    \n",
    "    iters = 1000\n",
    "    shuffled_results = np.zeros((len(bins)-1, iters))\n",
    "    \n",
    "    conn_str_copy = conn_str.copy()\n",
    "    \n",
    "    for i in range(iters):\n",
    "        print('Iteration', i)\n",
    "        \n",
    "        np.random.shuffle(conn_str_copy)\n",
    "        \n",
    "        binned_conn_str = {}\n",
    "        for correlation, strength in zip(res_corr, conn_str_copy):\n",
    "            bin_n = get_bin(correlation, bins)\n",
    "            if bin_n != -1:\n",
    "                if not bin_n in binned_conn_str:\n",
    "                    binned_conn_str[bin_n] = []\n",
    "                binned_conn_str[bin_n].append(strength)\n",
    "        \n",
    "        shuffled_results[:, i] = [np.mean(v) for v in binned_conn_str.values()]\n",
    "        \n",
    "    return shuffled_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d                = np.load('', allow_pickle=True).item() # Precomputed dataset path here\n",
    "res_corr         = d['res_corr']\n",
    "is_connected_arr = d['is_connected_arr']\n",
    "conn_str         = d['conn_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "plt.hist(res_corr[is_connected_arr==1], bins=200, facecolor='black');\n",
    "plt.xlabel('Response correlation')\n",
    "plt.ylabel('Number of pairs')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(4,4)\n",
    "save_plot(2, 'res_corr_hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-0.1, 0, 0.1, 0.2, 0.3, 0.4]\n",
    "bin_centres = bins[:-1]+np.diff(bins)[0]/2\n",
    "x = np.arange(len(bin_centres))\n",
    "\n",
    "connected_binned_data, _      = np.histogram(res_corr[is_connected_arr==1], bins=bins)\n",
    "all_binned_data, _            = np.histogram(res_corr, bins=bins)\n",
    "binned_connection_probability = connected_binned_data/all_binned_data\n",
    "\n",
    "null_dist = get_shuffled_binned_data_cossel_conprob (res_corr, is_connected_arr, bins)\n",
    "\n",
    "print(connected_binned_data)\n",
    "print(np.percentile(null_dist, 2.5, axis=1))\n",
    "print(np.percentile(null_dist, 97.5, axis=1))\n",
    "p_vals = [get_p_val(connected_binned_data[i], null_dist[i]) for i in range(len(connected_binned_data))]\n",
    "print(p_vals)\n",
    "\n",
    "fig = plt.figure(dpi=100, figsize=[6, 4])\n",
    "ax1 = plt.gca()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.bar(x-1/3, binned_connection_probability, facecolor='black', width=1/3)\n",
    "ax2.bar(x, [16/179, 37/279, 12/40, 5/14, 5/8], facecolor='gray', width=1/3)\n",
    "plt.xticks(np.arange(-1, len(bin_centres))+1/3, bins)\n",
    "ax1.set_xlabel('Response correlation')\n",
    "ax1.set_ylabel('Model connection prob.')\n",
    "ax2.set_ylabel('V1 connection prob.')\n",
    "format_plot(ax1, fontsize=20)\n",
    "format_plot(ax2, fontsize=20)\n",
    "ax2.spines['right'].set_visible(True)\n",
    "fig.set_size_inches(4,4)\n",
    "save_plot(2, 'res_corr_conn_prob_static')\n",
    "plt.show()\n",
    "\n",
    "print(get_cochrane_armitage(connected_binned_data, all_binned_data))\n",
    "\n",
    "save_connectivity_data(\n",
    "    model_name   = MODEL_NAME,\n",
    "    measure_name = 'response_correlation_conn_prob',\n",
    "    model        = binned_connection_probability,\n",
    "    target       = [16/179, 37/279, 12/40, 5/14, 5/8]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-0.1, 0, 0.1, 0.2, 0.3, 0.4]\n",
    "centred_bins = bins[:-1]+np.diff(bins)[0]/2\n",
    "\n",
    "def get_bin (v, bins):\n",
    "    for b in bins:\n",
    "        if v <= b:\n",
    "            return bins.index(b)-1\n",
    "    return -1\n",
    "\n",
    "binned_conn_str = {}\n",
    "for correlation, strength in zip(res_corr, conn_str):\n",
    "    bin_n = get_bin(correlation, bins)\n",
    "    if bin_n != -1:\n",
    "        if not bin_n in binned_conn_str:\n",
    "            binned_conn_str[bin_n] = []\n",
    "        binned_conn_str[bin_n].append(strength)\n",
    "    \n",
    "mean_data = [np.mean(v) for v in binned_conn_str.values()]\n",
    "\n",
    "null_dist = get_shuffled_binned_data_cossel_constr (res_corr, conn_str, bins) \n",
    "\n",
    "print(mean_data)\n",
    "print(np.percentile(null_dist, 2.5, axis=1))\n",
    "print(np.percentile(null_dist, 97.5, axis=1))\n",
    "p_vals = [get_p_val(mean_data[i], null_dist[i]) for i in range(len(mean_data))]\n",
    "print(p_vals)\n",
    "\n",
    "fig = plt.figure(dpi=100)\n",
    "ax1 = plt.gca()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(centred_bins, mean_data/np.percentile(null_dist, 50, axis=1), c='black')\n",
    "ax2.plot(centred_bins, [0, 0.045, 0.083, 0.547, 1], c='gray')\n",
    "ax1.set_xlabel('Response correlation')\n",
    "ax1.set_ylabel('Mean connection\\nstrength (normalized)')\n",
    "ax2.set_ylabel('Mean EPSP\\nstrength (mV)')\n",
    "format_plot(ax1, fontsize=20)\n",
    "format_plot(ax2, fontsize=20)\n",
    "ax2.spines['right'].set_visible(True)\n",
    "fig.set_size_inches(4,4)\n",
    "#save_plot(2, 'res_corr_conn_str_static')\n",
    "plt.show()\n",
    "\n",
    "save_connectivity_data(\n",
    "    model_name   = MODEL_NAME,\n",
    "    measure_name = 'response_correlation_conn_str',\n",
    "    model        = mean_data/np.percentile(null_dist, 50, axis=1),\n",
    "    target       = [0, 0.045, 0.083, 0.547, 1]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk]",
   "language": "python",
   "name": "conda-env-allensdk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
